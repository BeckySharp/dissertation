%space{-1mm}
\section{Indirect Evaluation: QA Task}
%space{-1mm}
%\label{sec-emnlp2016:qa}
\label{sec-emnlp2016:indirecteval}

%\todo{Describe the QA system and its features shortly, in 1 paragraph.}
The main objective of our work is to investigate the impact of a customized causal embedding model for question answering (QA). Following our direct evaluation, which solely evaluated the degree to which our models directly encode causality, here we evaluate each of our proposed causal models in terms of their contribution to a downstream real-world QA task.

Our QA system here uses the same standard reranking approach~\citep{jansen14} as in Chapter \ref{chapter:naacl2015}.
In this architecture, the candidate answers are initially extracted and ranked using a shallow information retrieval (IR) component, then they are re-ranked using a ``learning to rank'' approach (see Section \ref{sec-naacl2015:models} for more details on the IR component and resulting IR score).
In particular, we used SVM rank\footnote{ \url{http://www.cs.cornell.edu/people/tj/svm_light/svm_rank.html}}, a Support Vector Machines classifier adapted for ranking, and re-ranked the candidate answers with a set of features derived from both the initial IR score and the models we have introduced. For our model combinations (see Table \ref{tab:QA}), the feature set includes the IR score and the features from each of the models in the combination.
%We compare the performance of our causal models against the same vanilla embeddings model (vEmbed) used in Section \ref{sec-emnlp2016:directeval}, the vanilla alignment model (vAlign) of Fried et al.~\citeyear{fried2015higher} trained over the same corpus as the questions,  as well as the look-up baseline.
%

\subsection{Data}

% Our models were trained on open-domain resources, so 
We evaluate on a set of causal questions extracted from the Yahoo! Answers corpus\footnote{Freely available through Yahoo!'s Webscope
program ({\scriptsize {\tt research-data-requests@yahoo-inc.com}})} with simple surface patterns such as \emph{What causes ...} and ~\emph{What is the result of ...}\footnote{We lightly filtered these with stop words to remove non-causal questions, such as those based on math problems and the results of sporting events. Our dataset is freely available, conditioned on users having obtained the Webscope license.}.
We extracted a total of 3031 questions, each with at least four candidate answers, and we evaluated performance using five-fold cross-validation, with three folds for training, one for development, and one for testing. 

\subsection{Models and Features}

We evaluate the contribution of the bidirectional and noise-aware causal embedding models (cEmbedBi, and cEmbedBiNoise) as well as the causal alignment model (cAlign) and the causal convolutional neural network (cCNN).  These models are compared against three baselines: the vanilla embeddings (vEmbed), the lookup baseline (LU), and additionally a vanilla alignment model (vAlign) which is trained over 65k question-answer pairs from Yahoo! Answers.

The features\footnote{Due to the variety of features used, each feature described here is independently normalized to lie between 0.0 and 1.0.} we use for the various models are:

{ \flushleft \textbf{Embedding model features:}}
For both our vanilla and causal embedding models, we use the same set of features as in Section \ref{sec-naacl2015:models} \citep{fried2015higher}: the maximum, minimum, and average pairwise cosine similarity between question and answer words, as well as the overall similarity between the composite question and answer vectors.  
When using the causal embeddings, since the relation is directed, we first determine whether the question text is the cause or the effect\footnote{We do this through with simple regular expressions, \mbox{e.g., ``\^~[Ww]hat ([a-z]+ )\{0,3\}cause.+''}}, which in turn determines which embeddings to use for the question text and which to use for the candidate answer texts.  For example, in a question such as "\emph{What causes X?}", since \emph{X} is the effect, all cosine similarities would be found using the effect vectors for the question words and the cause vectors for the answer candidate words. 

{\flushleft \textbf{Alignment model features:}} Again, as in Section \ref{sec-naacl2015:models}, we use the same global alignment probability, $p(Q|A)$ of \citet{Surdeanu:11}. In our causal alignment model, we adapt this to causality as $p(\text{Effect}|\text{Cause})$, and again we first determine the direction of the causal relation implied in the question.  We once again include the additional undirected alignment features based on Jensen-Shannon distance, proposed more recently by \citet{fried2015higher}, in our vanilla alignment model.  However, due to the directionality inherent in causality, they do not apply to our causal model so there we omit them.

{\flushleft \textbf{Look-up feature:}} For the look-up baseline we count the number of times words from the question and answer appear together in our database of extracted causal pairs, once again after determining the directionality of the questions.  If the total number of matches is over a threshold\footnote{Empirically determined to be 100 matches.  Note that using this threshold performed better than simply using the total number of matches.}, we consider the causal relation to be established and give the candidate answer a score of 1; or a score of 0, otherwise.
