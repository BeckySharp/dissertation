
\section{Related Work}
\label{sec-emnlp2016:related work}
%\vspace{-2mm}

%QA with dedicated component
Addressing the need for %In the pursuit of %quest for building 
specialized solving methods in QA, 
Oh et. al~\citeyear{oh2013question} incorporate a dedicated causal component into their system, and note that it improves the overall performance.  However, their model is limited by the need for lexical overlap between a causal construction found in their knowledge base and the question itself.  Here, we develop a causal QA component that exploits specialized word embeddings to gain robustness to lexical variation.  
%which can model the likelihood of a causal link between two texts even when the exact lexical items were never observed together in the knowledge base.

% Embeddings in QA
There has been a vast body of work which demonstrates that word embeddings derived from distributional similarity are useful in many tasks, including question answering -- see \emph{inter alia}~\mbox{\cite{fried2015higher,yih13}}.  However, Levy and Goldberg~\citeyear{levy2015supervised} note that there are limitations on the type of semantic knowledge which is encoded in these general-purpose similarity embeddings. 
Therefore, here we build customized task-specific embeddings for causal QA.

%% Customized embeddings
Customized embeddings have been created for a variety of tasks, including semantic role labeling~\cite{fitzgerald2015semantic,woodsenddistributed}, and binary relation extraction ~\mbox{\cite{riedel2013relation}.}
%% For example, with semantic role labelling, custom embeddings have been learned for semantic frames, their arguments, and the roles of the arguments (e.g. \cite{fitzgerald2015semantic,woodsenddistributed}).  Riedel et al.~\citeyear{riedel2013relation} used distant supervision to learn embeddings for binary relations and argument pairs to perform automated database completion.  
%Like Riedel et al., we are interested in binary relations, but we train a dedicated embedding space for a single such relation, while they represent all relations in a single embeddding space.
Similar to Riedel et al., we train embeddings customized for specific relations, but we bootstrap training data using minimal supervision (i.e., a small set of patterns) rather than relying on distant supervision and large existing knowledge bases.  Additionally, while Riedel et al. represent all relations in a general embedding space, here we train a dedicated embedding space for just the causal relations. 
%\todo{remove: this is just text so that my citation doesn't fall across page boundaries, which makes latex cry}

In QA, embeddings have been customized to have question words that are close to either their answer words~\cite{bordes2014question}, or to structured knowledge base entries~\cite{yang2014joint}.  While these methods are useful for QA, they do not distinguish between different types of questions, and as such their embeddings are not specific to a given question type.

Additionally, embeddings have been customized to distinguish functional similarity from relatedness ~\cite{levy2014dependency,kielaspecializing}.
In particular, Levy and Goldberg train their embeddings by replacing the standard linear context of the target word with context derived from the syntactic dependency graph of the sentence.  For example, when given the word \emph{turing}, wheras a traditional embeddings model returns top associates containing topically related words such as \emph{non-deterministic} and \emph{finite-state}, the dependency-based model returns other tests (i.e., \emph{pauling, hotelling,} and \emph{hamming}).
In this work, we make use of this extension to arbitrary context in order to train our embeddings with contexts derived from binary causal relations.  We extract cause-effect text pairs such that the cause text becomes the \emph{target} text and the effect text serves as the \emph{context}. 

Recently, Faruqui et al.\citeyear{faruqui2016problems} discussed issues surrounding the evaluation of similarity word embeddings, including the lack of correlation between their performance on word-similarity tasks and ``downstream'' or real-world tasks like QA, text classification, etc.  As they advocate, in addition to a direct evaluation of our causal embeddings, we also evaluate them independently in a downstream QA task.  We provide the same comparison for two alternative approaches (an alignment model and a convolutional neural network model), confirming that the direct evaluation performance can be misleading without the task-specific, downstream evaluation. 

%\todo{better intro target/context} In this way, words which \emph{cause similar things} would be top-associates of each other.  

%In the search for ways to represent the semantic information encoded in words and text, there have been several methods proposed which are based on the distributional hypothesis of \todo{cite}.  The distributional hypothesis asserts that words which are semantically similar will tend to occur in similar word contexts.  One of the methods based on this hypothesis, the Skipgram algorithm \todo{cite and link}, or \texttt{word2vec}\footnote{\todo{link!}}, has been widely used for far-ranging NLP tasks.  This algorithm maps words onto high-dimensional dense vectors (embeddings) in such a way that words which are more similar to each other are closer together in the high-dimensional space.%, often measured through cosine similarity.  

%Levy and Goldberg also suggest that the traditional skipgram vectors encode broad topical similarity, and propose an extension of the algorithm which replaces the linear context of a given target word with arbitrary context.  
%While there we make use of the same  rather than topical similarity.  For example, when given the word \emph{turing}, wheras the traditional skipgram model returns top associates containing topically related words such as \emph{non-deterministic} and \emph{finite-state}, the dependency-based model returns other tests (i.e., \emph{pauling, hotelling,} and \emph{hamming}).

%While the specific implementation of Levy and Goldberg~\citeyear{levy2014dependency} uses dependency-derived contexts for training, their extension of the algorithm allows for \emph{arbitraty} contexts.  
%Additionally, though seldom used, the skipgram algorithm produces two sets of embeddings for each word, one for when the word serves as a target word and another for when the word serves as a context word.  Here, since the relation of interest is inherently directional, both sets of embeddings are meaningful, and so we make use of both -- the target vectors when a given word appears as a cause and the context vectors when that word appears as an effect.




%--Causal Patterns
With respect to extracting causal relations from text, Girju et al.~\citeyear{girju2002text} use modified Hearst patterns~\cite{hearst1992automatic} to extract a large number of potential cause-effect tuples, where both causes and effects must be nouns.
However, Cole et al.~\citeyear{cole2005lightweight} show that these nominal-based causal relations account for a relatively small percentage of all causal relations, and for this reason, \cite{yang2014multi} allow for more elaborate argument structures in their causal extraction by identifying verbs, and then following the syntactic subtree of the verbal arguments to construct their candidate causes and effects. 
Additionally, Do et al.~\citeyear{do2011minimally} observe that nouns as well as verbs can signal causality.  
We follow these intuitions in developing our causal patterns by using both nouns and verbs to signal potential participants in causal relations, and then allowing for the entire dominated structures to serve as the cause and/or effect arguments.

%Khoo did this over newspapers too


%\todo{POSSIBLY MOVE TO METHODS: 
%Khoo et al.~\citeyear{khoo1998automatic} also extract causal tuples using linguistic patterns, and in their error analysis they find that the majority of their errors of commission (i.e., %mislabelling a construction as casual) result from lexical ambiguity.  That is, several lexical constructions which can signal causality are also used in non-causal senses.  To minimize the noise %in the extracted pairs, we restrict ourselves to patterns with low ambiguity. 
%Further, inspired by bootstrapping literature~\cite{riloff1996automatically}, we rank the extracted tuples by their likelihood of being noisy using a formula driven by mutual information, and %adjust the training process of the embedding models to use this information.
%}

