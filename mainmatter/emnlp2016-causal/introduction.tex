
\section{Introduction}
\label{sec-emnlp2016:introduction}
%\vspace{-2mm}

Question answering (QA), i.e., finding short answers to natural language questions, is one of the most important but challenging 
tasks on the road towards natural language understanding~\cite{Etzioni:11}. 
A common approach for QA is to prefer answers that are closely related to the question, where relatedness is often determined using lexical semantic models such as word embeddings~\cite{yih13,jansen14,fried2015higher}. 
%Many QA systems answer questions by looking for answers that are closely related to the question, often as determined with lexical semantic word embeddings~\todo{citation}.  
While appealing for its robustness to natural language variation, this one-size-fits-all approach does not take into account the wide range of distinct question types that can appear in any given question set, and that are best addressed individually~\cite{chu2004ibm,ferrucci2010building,clark2013study}.  

Given the variety of question types, we suggest that a better approach is to look for answers % which are not simply closely related to the question, 
that are related to the question \emph{through the appropriate relation}, e.g., a causal question should have a cause-effect relation with its answer.
If we adopt this view, and continue to work with embeddings as a mechanism for assessing relationship,
this raises a key question: how do we train and use task-specific embeddings cost-effectively? 
Using causality as a use case, we answer this question with a framework for producing causal word embeddings with minimal supervision, and a demonstration that such task-specific embeddings significantly benefit causal QA. 
%Adopting this view, here we propose using task-specific word embeddings that combine the robustness and versatility of word embeddings with the precision of addressing a specific question type.  
%As a use case, we focus on producing custom embeddings with minimal supervision that capture causality and that are thus directly applicable to causal QA.

%\todo{REMOVE?: One important hurdle for QA is that there isn't a single ``universal engine'' that can answer any question, but rather a collection of methods, each tailored to a specific question type (e.g., factoid, definitional, or causal).
%This has been repeatedly observed throughout QA research, in various domains
%\cite{chu2004ibm,ferrucci2010building,clark2013study}. 
%Building from this observation, this paper proposes a framework for developing specific QA solving methods, and, in particular, on the rapid bootstrapping of knowledge resources needed by these solving methods. We encode this knowledge as customized embedding vectors, and demonstrate that they can be generated with minimal supervision. As a use case, we focus on producing custom embeddings that capture \textit{causality} and that are thus directly applicable to causal QA. }

In particular, the contributions of this work are:

%{\flushleft {\bf (1)}} 
%A novel approach for question answering that uses task-specific distributional similarity models 

{\flushleft {\bf (1)}} 
A methodology for generating causal embeddings cost-effectively by bootstrapping cause-effect pairs extracted from free text using a small set of seed patterns, e.g., {\em X causes Y}. 
%We propose a method to generate knowledge resources for causal questions 
%We demonstrate that knowledge resources for causal questions can be generated by bootstrapping cause-effect pairs extracted from free text using a small set of high-precision patterns, e.g., {\em X causes Y}. 
We then train dedicated embedding (as well as two other distributional similarity) models over this data. \citet{levy2014dependency} have modified the algorithm of\citet{mikolov2013distributed} to use an arbitrary, rather than linear, context. Here we make this context task-specific, i.e., the context of a cause is its effect.
%embedding models (as well as alignment and convolutional neural network models) over this data. 
Further, to mitigate sparsity and noise, our models are bidirectional, and noise aware (by incorporating the likelihood of noise in the training process). 
%We achieve the latter by weighting the examples based on the likelihood that they are truly causal rather than simply associative. 

{\flushleft {\bf (2)}} The insight that QA benefits from task-specific embeddings. % , and a demonstration that this approach significantly improves performance. 
We implement a QA system that uses the above causal embeddings to answer questions and demonstrate that they significantly improve performance over a strong baseline. Further, we show that causal embeddings encode complementary information to vanilla embeddings, even when trained from the same knowledge resources. 

{\flushleft {\bf (3)}} An analysis of direct vs. indirect evaluations for task-specific word embeddings. 
We evaluate our causal models both  {\em directly}, in terms of measuring their capacity to rank causally-related word pairs over word pairs of other relations, as well as {\em indirectly} in the downstream causal QA task. 
%Importantly, the above knowledge acquisition process is completely independent from these evaluation tasks, e.g., the objective function of the embedding model does not include any information from the QA task, which guarantees modularity. 
In both tasks, our analysis indicates that including causal models significantly improves performance. 
However, from the direct evaluation, it is difficult to estimate which models will perform best in real-world tasks. Our analysis re-enforces recent observations about the limitations of word similarity evaluations~\cite{faruqui2016problems}: we show that they have limited coverage and may align poorly with real-world tasks.

%{\flushleft {\bf (3)}} For causal QA, we show that causal embeddings encode complementary information to vanilla embeddings, even when trained from the same knowledge resources. 

%the models that include causal embeddings perform significantly better than the models that do not. Further, for causal QA, we show that causal embeddings are complementary to vanilla embeddings, underlining the complexity of this QA task, which must simultaneously capture causality and associations driven by distributional similarity. \todo{reword? seems like we're contradicting our earlier statement...}

%{\flushleft {\bf (4)}} Finally, we show that there are discrepancies between direct and indirect evaluations, i.e., no model performs best in both tasks. Our analysis re-enforces recent observations about the limitations of narrow word similarity evaluations~\cite{faruqui2016problems}, in that they both have limited coverage, and can poorly align with real world tasks.
