
%\twocolumn[\centering \Large \bf Creating Causal Embeddings for Question Answering \\with Minimal Supervision \par
%~\\
%
%\large \bf Anonymous EMNLP submission
%~\\
%~\\
%]

%\begin{abstract}
%A common model for question answering (QA) is that a good answer is one that is closely related to the question, where relatedness is often determined using general-purpose lexical models such as word embeddings. 
%We argue that a better approach is to look for answers that are related to the question in a {\em relevant way}, according to the information need of the question,
%%We argue that a better approach is to look for answers that are related to the question in {\em the right way} \todo{"the right way" doesn't say much... Can we say something like "in a way relevant to the type of information need, or something like that?}, 
%which may be determined through task-specific embeddings. 
%With causality as a use case, we implement this insight in three steps. First, we generate causal embeddings cost-effectively by bootstrapping cause-effect pairs extracted from free text using a small set of seed patterns. Second, we train dedicated embeddings over this data, by using task-specific contexts, i.e., the context of a cause is its effect. Finally, we extend a state-of-the-art reranking approach for QA to incorporate these causal embeddings. We evaluate the causal embedding models both \emph{directly} with a casual implication task,
%% \todo{"Word similarity" makes it sound like we do lexical similarity... Can you say something causal implication?}, 
% and \emph{indirectly}, in a downstream causal QA task using data from Yahoo! Answers. We show that explicitly modeling causality improves performance in both tasks. In the QA task our best model achieves 37.3\% P@1, significantly outperforming a strong baseline by 7.7\% (relative). 
%% ms: not sure if we should discuss the differences between the 2 tasks here; we might not have space; it might dilute the message.
%
%%
%%Question answering (QA) is a difficult task, complicated by the variety of question types represented in any given question set.  In this work we propose addressing question types individually through the use of dedicated relation embeddings, and here focus on causal relations. 
%%We train causal embeddings (as well as two other popular distributional similarity models) on causal tuples extracted from free text resources with minimal supervision, using a small set of high-precision patterns.   
%%We evaluate these causal models both \emph{directly} in terms of their ability to detect causality, and \emph{indirectly}, in terms of their utility on a causal subset of Yahoo! Answers.
%%In both tasks, we show that explicitly modeling causality significantly improves performance, and in the QA task our best model achieves 37.3\% precision at one, outperforming a strong information retrieval and lexical semantic baseline by 7.7\% (relative). 
%%Importantly, we also show that the results of these two evaluations are \emph{not} identical: a given model's performance on the direct evaluation does not necessarily transfer to the more complex, real-world QA task.  
%\end{abstract}

\chapter{EMNLP2016 - CAUSAL EMBEDDINGS\label{chapter:emnlp2016}}



\input{mainmatter/emnlp2016-causal/introduction}
\input{mainmatter/emnlp2016-causal/relatedwork}
\input{mainmatter/emnlp2016-causal/approach}
\input{mainmatter/emnlp2016-causal/causalextraction}
\input{mainmatter/emnlp2016-causal/models}
\input{mainmatter/emnlp2016-causal/directeval}
\input{mainmatter/emnlp2016-causal/qamodel}
\input{mainmatter/emnlp2016-causal/qa}

%\vspace{-1mm}
\section{Conclusion}
%\vspace{-1mm}
We presented a framework for creating customized embeddings tailored to the information need of causal questions.  We trained three popular models (embedding, alignment, and CNN) using causal tuples extracted with minimal supervision by bootstrapping cause-effect pairs from free text, and evaluated their performance both directly (i.e., the degree to which they capture causality), and indirectly (i.e., their real-world utility on a high-level question answering task). 


%We note that the results of these two evaluations are not identical; higher performance on the direct evaluation does \emph{not} necessarily correlate with higher performance in the QA task.
We showed that models that incorporate a knowledge of causality perform best for both tasks. 
Our analysis suggests that the models that perform best in the real-world QA task are those that have consistent performance across the precision-recall curve in the direct evaluation.
In QA, where the vocabulary is much larger, precision must be balanced with high-recall, and this is best achieved by our causal embedding model.  Additionally, we showed that vanilla and causal embedding models address different information needs of questions, and can be combined to improve performance. 

Extending this work beyond causality, we hypothesize that additional embedding spaces customized to the different information needs of questions would allow for robust performance over a larger variety of questions, and that these customized embedding models should be evaluated both directly and indirectly to accurately characterize their performance. 

%We introduced a methodology for producing causal embedding models cost-effectively by bootstrapping cause-effect pairs extracted from free text using a small set of seed patterns, and then training dedicated embedding models over this data using task-specific contexts, i.e., where the context of a cause is its effect. We then used these causal embedding models to implement a dedicated reranking model for causal QA. 

%We evaluated the generated embedding models both directly, in a word similarity task, and indirectly, in the downstream QA task. Our analysis yielded multiple observations. First, causal embeddings significantly outperform vanilla embeddings in both tasks, demonstrating the importance of having dedicated models for the task at hand. Second, for QA, the causal embeddings stack well with vanilla ones, highlighting that QA is a complex task, where solving methods need to address multiple information needs. Third, we note that the results of these two evaluations are not identical; higher performance on the direct evaluation does not necessarily correlate with higher performance in the QA task. Our analysis suggests that the performance on the direct evaluation is driven by precision, whereas for the real-world QA task, where the vocabulary is much larger, the precision must be balanced with high-recall which is best achieved by our causal embedding model.  

%We hypothesize that additional embedding spaces customized to the different information needs of questions would allow for robust performance over a larger variety of questions, and that these customized embedding models should be evaluated both directly and indirectly to accurately characterize their performance. 

\section*{Resources}
All code and resources needed to reproduce this work are  available at \url{http://clulab.cs.arizona.edu/data/emnlp2016-causal/}.

% ms: removed for anonymous submission
\section*{Acknowledgments}
We thank the Allen Institute for Artificial Intelligence for funding this work.
Additionally, this work was partially funded by the Defense Advanced
Research Projects Agency (DARPA) Big Mechanism
program under ARO contract W911NF-14-1-0395.


\newpage
%\bibliography{emnlp2016}
%\bibliographystyle{emnlp2016}

%\end{document}
