%Monolingual alignment models have been shown to boost the performance of question answering systems by "bridging the lexical chasm" between questions and answers.


%\section{Alignment for question answering}
%\label{sec-naacl2015:intro}
%\section{NAACL 2015 Related Work}
%\label{sec:related_work_naacl2015}
%\vspace{-2mm}


For the task of question answering (QA), lexical semantic models have shown promise in bridging \citet{Berger:00}'s "lexical chasm," or the lack of lexical overlap between questions and their answers.  In general, these models can be classified into alignment models \citep{echihabi2003noisy,Soricut:06,Riezler:etal:2007,Surdeanu:11,yao2013}, which are based on the repurposing of machine translation models to operate over aligned question-answer pairs within a single language (and hence require structured training data), and language models ~\citep{jansen14,sultan-etal:2014:TACL,yih13}, which operate over free text.  
This training data requirement of alignment models is their main limitation, as it is difficult to obtain in specialized domains or low-resource languages.
In this Chapter, we focus on closing this gap in resource availability by proposing two inexpensive methods for training alignment models solely using free text by generating artificial question-answer pairs from discourse structures. 
%Our approach is driven by two representations of discourse: a shallow sequential representation, and a deep one based on Rhetorical Structure Theory. 
%Here, we focus on closing this gap in resource availability by developing a method to train an alignment model over free text by making use of discourse structures. 

\section{Chapter overview}

The remainder of this Chapter is organized as follows.  We discuss previous work in Section \ref{sec-naacl2015:relatedwork}.  Then, in Section \ref{sec-naacl2015:approach} we describe our two approaches to generating pairs of artificially aligned text spans.  Then, in Section \ref{sec-naacl2015:models} we describe our models and model features in more detail.  In Section \ref{sec-naacl2015:experiments} we detail the experimental setup used to evaluate the proposed models on two corpora from different genres and domains: one from Yahoo! Answers and one from the biology domain, and two types of non-factoid questions: manner (questions about the way in which something happens, often beginning with ``How'') and reason (questions about the reason something happens, typically beginning with ``Why'').  In Section \ref{sec-naacl2015:results} we provide the results, showing that these alignment models trained directly from discourse structures imposed on free text
improve performance considerably over an information retrieval baseline and a neural network language model trained on the same data.  Finally, in Section \ref{sec-naacl2015:conclusion} we draw conclusions about our approach.


\section{Related Work}
\label{sec-naacl2015:relatedwork}
%\subsection{Discourse for Question Answering}
Discourse has been previously applied to QA to help identify answer candidates that contain explanatory text.  For example, \citet{Verberne:2007} conducted an initial analysis of using discourse features derived from Rhetorical Structure Theory~\citep[RST;][]{mann88} for answer candidate selection, and concluded that while discourse features appeared useful, automated discourse parsing tools were required to test the idea on a larger scale.  
\citet{jansen14} proposed an answer reranking model that used both shallow and deep discourse features.  The shallow features were based on segmenting text at occurrences of a set of discourse markers \citep{marcu97} (i.e., words that typically indicate a discourse boundary) such as \textit{and, in, that, for, if, as, not, by,} and \textit{but}.  The deep features were based on discourse parsing the text.  These features were used in combination to identify useful answer structures in large answer collections across different tasks and genres.  Here we also use discourse to impose structure on free text, but we use this to create inexpensive knowledge resources for monolingual alignment. However, our work is conceptually \textit{complementary} to that of Jansen et al. -- where they explored largely unlexicalized discourse structures to identify explanatory text (i.e., their features do not incorporate the actual text itself), we use discourse to learn lexicalized models that encode semantic similarity.

%\subsection{Artificial alignments}
Our work is conceptually closest to that of \citet{hickl2006recognizing}, who also created artificially aligned pairs, but for the task textual entailment (i.e., determining whether or not a given span of text entails another).  Taking advantage of the structure of news articles, wherein the first sentence tends to provide a broad summary of the article's contents, Hickl et al. generated text pairs to train an alignment model by aligning the first sentence of each article with its headline.  By making use of automated discourse parsing, here we go further and impose alignment structure over an entire text, allowing us to gain more training data from our resources.


%
% Example of alignment models
%
%\begin{table}[t!]
%\begin{center}
%\begin{scriptsize}
%\begin{tabular}{l|p{60mm}}
%Passage	& Bob likes apples, which grow in his orchard.  He uses them for cider.  \\
%\hline
%Sequential & Bob likes apples, which grow in his orchard. $\rightarrow$ He uses them for cider. \\
%\hline
%RST & Bob likes apples, $\rightarrow$ which grow in his orchard. \\
% & Bob likes apples, which grow in his orchard. $\rightarrow$ He uses them for cider. \\
%
%
%\end{tabular}
%\end{scriptsize}
%%\vspace{-4mm}
%\caption{{\footnotesize \label{font-table} 
%An example of the alignments produced by the two discourse models.  While the sequential model aligns at sentence granularity capturing only intersentence information, the RST model aligns on finer EDU boundaries, capturing both inter/intrasentence alignments.
%}}
%\vspace{-4mm}
%
%\label{tab:examples}
%\end{center}
%\end{table}


\begin{figure}[t!]
\begin{center}
\includegraphics[width=100mm]{mainmatter/naacl2015-alignment/rst2a.pdf}
%space{-2mm}
\caption{{\small An example of the alignments produced by the two discourse models.  The sequential model aligns pairs of consecutive sentences, capturing intersentence associations such as \emph{cider--apples}, and \emph{orchard--autumn}.  The Rhetorical Structure Theory based model generates alignment pairs from participants in all (binary) discourse relations, capturing both intrasentence and intersentence alignments, including 
\emph{apples--orchard, cider--apples}, and \emph{cider--autumn}.}}
\label{fig:examples}
\end{center}
\end{figure}

\section{Approach}
\label{sec-naacl2015:approach}

A written text is not simply a collection of sentences, but rather a flowing narrative where sentences and sentence elements depend on each other for meaning -- a concept known as cohesion~\citep{halliday2014cohesion}.  
Here we examine two methods for generating alignment training data from free text that make use of cohesion: a shallow method that uses only intersentence structures, and a deep method that uses both intrasentence and intersentence structures.
We additionally attempt to separate the contribution of discourse from that of alignment in general by comparing these models against a baseline alignment model which aligns sentences at random.

The first model, the sequential discourse model (SEQ), is based on the intuition that each sentence continues the narrative of the previous one, so for it we create artificial question-answer pairs from all pairs of consecutive sentences.
% ms: no space
%This is similar to a right-attachment baseline in dependency parsing, 
%but operating at sentence granularity rather than word.
Thus, this model takes advantage of intersentence cohesion by aligning the content words\footnote{In pilot experiments, we found that aligning only nouns, verbs, adjectives, and adverbs yielded higher performance.} in each sentence with the content words in the following sentence.  For example, in the passage in Figure \ref{fig:examples}, this model would associate \emph{cider} in the first sentence with \emph{apples} and \emph{orchard} in the second sentence.

The second model uses Rhetorical Structure Theory (RST) to capture discourse cohesion both within and across sentence boundaries.  
We extracted RST discourse structures using an in-house parser~\citep{Surdeanu:15}, which follows the architecture introduced by \citet{hernault10} and \citet{feng12}.

\begin{table}[t!]
\begin{center}
\begin{tabular}{l}
\toprule
\textbf{Discourse Relations}  \\
\midrule
attribution, background, cause, comparison, condition, contrast, elaboration,\\ enablement, evaluation, explanation, joint, manner-means, topic-comment,\\ summary, temporal, topic-change, textual-organization, same-unit\\
\end{tabular}
\caption{ \label{tab:rst} 
The 18 discourse relation labels that can be assigned by the Rhetorical Structure Theory (RST) parser of \citet{Surdeanu:15}.
}
%\vspace{-4mm}

\end{center}
\end{table}

The parser first segments text into elementary discourse units, which may be at sub-sentence granularity, then recursively connects neighboring units with binary discourse relations, such as \emph{Elaboration} or \emph{Contrast} (see Table \ref{tab:rst} for the full set of discourse relations).
%\footnote{The RST parser performs better on relations which occur more frequently.  We use only relations that occurred at least 1\% of the time.  This amounted to six relations: \emph{elaboration}, \emph{attribution}, \emph{background}, \emph{contrast}, \emph{same-unit}, and \emph{joint}. Using all relations slightly improves performance by 0.3\% P@1.} 
%Our parser differs from previous work with respect to feature generation in that we implement all features that rely on syntax using solely dependency syntax. For example, a crucial feature used by the parser is the dominance relations of \citet{soricut2003}, which capture syntactic dominance between discourse units located in the same sentence. While originally these dominance relations were implemented using constituent syntax, we provide an equivalent implementation that relies on dependency syntax. The main advantage to this approach is speed: the resulting parser performs at least an order of magnitude faster than the parser of \citet{feng12}. 

We generate artificial alignment pairs from this imposed structure by aligning the governing text (nucleus) with its dependent text (satellite).\footnote{Pilot experiments showed that this direction of alignment performed better than aligning from satellite to nucleus.} 
 Turning again to the example in Figure \ref{fig:examples}, this RST-based model captures additional alignments that are both intrasentence, e.g., \emph{apples--orchard}, and intersentence, e.g., {\em cider--autumn}. 
% intersentence associations of the sequential baseline, in addition it finds an intrasentence association between \emph{apples} and \emph{orchard}. 

Intuitively, we expect that some discourse relations would correspond with the specific question types: \textit{How} questions may correspond with \textit{elaboration} relations, \textit{Why} questions with \textit{explanation} relations, causal questions with \textit{cause} relations, etc.  On the other hand, some relations are more general (such as the \textit{joint} relation, which indicates text contained in a list or disjunction), and would likely be applicable to all questions.  While we leave this exploration of relations and question types to future work, we discuss addressing different question types individually with the approach proposed in Chapter \ref{chapter:emnlp2016}. 
%\todo{The random alignment baseline (RND) was created in a similar fashion to the SEQ model, except that the sentences were randomly shuffled first.  In the open domain this shuffling took place within a document, and in the biology domain it was done across the entire of the textbook.}
